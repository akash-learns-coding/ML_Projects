# -*- coding: utf-8 -*-
"""Creditworthiness.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k_wi6mHo4VcAJKuvWHdm5eFFlvNHLy6h
"""

# 1. Imports
import pandas as pd
import numpy as np
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# 2. Load Dataset
data = fetch_openml(data_id=46116, as_frame=True)
X = data.data
y = (data.target == 'bad').astype(int)  # 1 = bad credit risk

# 3. Preprocessing
cat_cols = ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose']
num_cols = ['Duration', 'Credit amount', 'Age']

preprocessor = ColumnTransformer([
    # Categorical features: impute missing with 'missing', then encode
    ('cat', Pipeline([
        ('impute', SimpleImputer(strategy='constant', fill_value='missing')),
        ('encode', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))
    ]), cat_cols),

    # Numerical features: impute with mean, then scale
    ('num', Pipeline([
        ('impute', SimpleImputer(strategy='mean')),
        ('scale', StandardScaler())
    ]), num_cols)
])

# 4. Pipeline
pipe = Pipeline([
    ('prep', preprocessor)
])
X_processed = pipe.fit_transform(X)

# 5. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.25, random_state=42, stratify=y)

# 6. Train Models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced'),
    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced')
}

for name, model in models.items():
    print(f"\n=== {name} ===")
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    proba = model.predict_proba(X_test)[:, 1]
    print(classification_report(y_test, preds))
    print(f"ROC AUC Score: {roc_auc_score(y_test, proba):.3f}")

# 7. Plot ROC Curves
plt.figure(figsize=(8,6))
for name, model in models.items():
    proba = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, proba)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc_score(y_test, proba):.2f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend()
plt.grid(True)
plt.show()